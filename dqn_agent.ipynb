{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Library Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np                  # Numpy numerical library\r\n",
    "import pandas as pd                 # Pandas for dataframes manipulation\r\n",
    "import tensorflow as tf             # TensorFlow for neural networks and deep learning APIs\r\n",
    "import matplotlib.pyplot as plt     # Plotting\r\n",
    "%matplotlib inline                  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "BATCH_SIZE = 512                # Default batch size\r\n",
    "TRAIN_SPLIT_PERCENT = 0.9       # 90% of the data for training, 10% for testing    \r\n",
    "\r\n",
    "class DataLoader:\r\n",
    "    # Take in a csv file and extracts features and labels\r\n",
    "    def __init__(self, csv_filepath, batch_size):                          \r\n",
    "        \r\n",
    "        self.df_samples = pd.read_csv(csv_filepath)                 # Create a pandas dataframe\r\n",
    "        self.numpy_samples = self.df_samples.to_numpy()\r\n",
    "        \r\n",
    "        self.states_features = self.numpy_samples[:, 1:self.numpy_samples.shape[1]-1]               # Take the feature values for states, also ignore first column for IDs  \r\n",
    "        self.feature_dim = self.states_features.shape[1]                                        \r\n",
    "        self.actions_labels = self.numpy_samples[:, -1].reshape(-1, 1)                              # The action labels separated from the labels\r\n",
    "        self.actions_classes = np.amax(self.actions_labels) + 1                                     # Number of different action classes to set the output layer dimensions (+1 bec starts at zero)\r\n",
    "        self.train_batches, self.test_batches = self.prepare_batches(batch_size, train_split_percent= TRAIN_SPLIT_PERCENT)\r\n",
    "        print(\"Dataset successfully loaded with {} training batches, and {} testing batches with {} batch size.\".format(\r\n",
    "            len(self.train_batches), len(self.test_batches), self.n_batches\r\n",
    "        ))\r\n",
    "        \r\n",
    "    def prepare_batches(self, batch_size, train_split_percent):\r\n",
    "        states_t = self.states_features[:-1, :]           # Considered as S(t)\r\n",
    "        states_t_plus_one = self.states_features[1:, :]   # Considered as S(t+1)\r\n",
    "        actions_star_t = self.actions_labels[:-1, :]      # Considered as a*(t)\r\n",
    "\r\n",
    "        whole_generic_samples = np.hstack((states_t, actions_star_t, states_t_plus_one))            # Stack the whole dataset as described in the paper\r\n",
    "\r\n",
    "        np.random.shuffle(whole_generic_samples)          # Shuffle the dataset\r\n",
    "        \r\n",
    "        self.n_samples = whole_generic_samples.shape[0]\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.n_batches = np.ceil(self.n_samples / self.batch_size).astype(np.uint32)\r\n",
    "\r\n",
    "        train_batches = []        # Empty list to hold the batches of whole data\r\n",
    "        test_batches = []\r\n",
    "\r\n",
    "        # Prepare the data into batches\r\n",
    "        for i in range(self.n_batches):\r\n",
    "            start = i * batch_size\r\n",
    "            end = (i + 1) * batch_size\r\n",
    "            curr_batch = whole_generic_samples[start:end, :]\r\n",
    "            if (i / self.n_batches) < train_split_percent:    \r\n",
    "                train_batches.append(curr_batch)\r\n",
    "            else:\r\n",
    "                test_batches.append(curr_batch)\r\n",
    "        \r\n",
    "        self.n_train_batches = len(train_batches)\r\n",
    "        self.n_test_batches = len(train_batches)\r\n",
    "        return train_batches, test_batches\r\n",
    "    \r\n",
    "    # Function that takes in the 2D arrays of data and converts lo lists of tuples to be compatible with looping while training\r\n",
    "    # TODO: Enhancing this function\r\n",
    "    def tupelize(self, array):\r\n",
    "        list_of_tuples = list(zip(array.T[0], array.T))\r\n",
    "        return list_of_tuples \r\n",
    "\r\n",
    "    # Function to get the unique rows representing unique states, returns a numpy array of rows\r\n",
    "    def get_unique_rows(self):\r\n",
    "        self.unique_rows = np.unique(self.states_features, axis = 0)\r\n",
    "        return self.unique_rows\r\n",
    "\r\n",
    "    # Get the pandas dataframe for the data, returns a pandas dataframe\r\n",
    "    def get_dataframe(self):    \r\n",
    "        return self.df_samples\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model and Classes Definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "Q_OUT_DIM = 1\r\n",
    "LEARNING_RATE = 0.001       # Gradient-descent learning rate\r\n",
    "REPLAY_MEMORY_SIZE = 50     # Size for RL replay memory\r\n",
    "UPDATE_TARGET_EVERY = 5     \r\n",
    "EPSILON = 0.8               # Epsilon value for the epsilon greedy policy selection\r\n",
    "LAMBDA = 0.1                # Discount factor for loss calculation\r\n",
    "EPOCHS = 10\r\n",
    "\r\n",
    "# Creating our main class for our DQN\r\n",
    "class DeepQNet:\r\n",
    "    \r\n",
    "    def __init__(self, dataset):\r\n",
    "        self.data = dataset                                         # Storing the data in our QNet            \r\n",
    "        self.input_dim = dataset.feature_dim + 1                    # State feature dim + 1 (for actions)\r\n",
    "        self.output_dim = Q_OUT_DIM                               \r\n",
    "        \r\n",
    "        self.model = self.create_model()                            # Main model that gets trained every step \r\n",
    "        self.target_model = self.create_model()                     # Target model we predict against each step\r\n",
    "        self.target_model.set_weights(self.model.get_weights())     # To make all the initial weights the same\r\n",
    "\r\n",
    "        # Defining the action-set\r\n",
    "        self.action_set = np.arange(self.data.actions_classes).astype(np.uint16).tolist() # List of all possible actions [0, 1, ... actions_classes]\r\n",
    "\r\n",
    "        # Used to count when to update target network with main network's weights\r\n",
    "        self.target_update_counter = 0\r\n",
    "    \r\n",
    "    def create_model(self):\r\n",
    "        # Definition of the neural network architecture mentioned in the paper (3 relu feedforward layers)\r\n",
    "        model = tf.keras.Sequential()\r\n",
    "        model.add(tf.keras.layers.Input(self.input_dim))                        # Input dimension of the state-vector\r\n",
    "        model.add(tf.keras.layers.Dense(128, activation= \"relu\"))\r\n",
    "        model.add(tf.keras.layers.Dense(128, activation= \"relu\"))\r\n",
    "        model.add(tf.keras.layers.Dense(self.output_dim , activation= \"relu\"))       # Output is value function\r\n",
    "        model.compile(loss=\"mse\", optimizer=tf.optimizers.Adam(lr= LEARNING_RATE), metrics=['accuracy'])\r\n",
    "        return model\r\n",
    "\r\n",
    "    # Prints the model details\r\n",
    "    def summary(self):\r\n",
    "        self.model.summary()\r\n",
    "\r\n",
    "    def get_reward(self, predicted_actions, optimal_actions):\r\n",
    "        predicted_actions = np.asarray(predicted_actions).reshape(-1)\r\n",
    "        optimal_actions = np.asarray(optimal_actions).reshape(-1)\r\n",
    "        reward_vector = np.equal(predicted_actions, optimal_actions).astype(np.uint32)\r\n",
    "        return reward_vector\r\n",
    "\r\n",
    "    # Function to implement the epsilon-greedy policy selection, returns the index of the selected action\r\n",
    "    def greedy(self, actions_values_vec, epsilon):\r\n",
    "        num_in_curr_batch = actions_values_vec.shape[1]\r\n",
    "        selections = []\r\n",
    "        for i in range(num_in_curr_batch):\r\n",
    "            p = np.random.uniform(low=0.0, high=1.0)\r\n",
    "            if p < epsilon:\r\n",
    "                curr_actions_values = actions_values_vec[:, i].reshape(-1)\r\n",
    "                selections.append(np.argmax(curr_actions_values))\r\n",
    "            else:\r\n",
    "                random_selection = np.random.randint(low=0, high=self.data.actions_classes)\r\n",
    "                selections.append(random_selection)\r\n",
    "        \r\n",
    "        selections = np.asarray(selections).reshape(-1, 1)\r\n",
    "\r\n",
    "        return selections\r\n",
    "\r\n",
    "    # Function to process the batch and split the S(t), a*(t), and S(t+1)\r\n",
    "    def process_batch(self, batch):\r\n",
    "        current_states = batch[:, :self.data.feature_dim]\r\n",
    "        optimal_actions = batch[:, self.data.feature_dim]\r\n",
    "        next_states = batch[:, self.data.feature_dim+1 :]\r\n",
    "        return current_states, optimal_actions, next_states\r\n",
    "\r\n",
    "    def get_input_vector(self, current_states, action):\r\n",
    "        action_vector = np.full((current_states.shape[0], 1), fill_value= action)\r\n",
    "        input_vector =  np.hstack((current_states, action_vector))\r\n",
    "        return input_vector\r\n",
    "\r\n",
    "    # Function to get the vectorized output of the batched-samples\r\n",
    "    def get_batch_vector_out(self, lst):\r\n",
    "        nparr = np.asarray(lst).squeeze() \r\n",
    "        if nparr.ndim < 2:\r\n",
    "            nparr = np.reshape(nparr, (nparr.shape[0], 1))\r\n",
    "        return nparr\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        \r\n",
    "        batches = self.data.train_batches               # Get the batches\r\n",
    "        self.target_update_counter = 0                  # The update counter \r\n",
    "\r\n",
    "        for epoch in range(EPOCHS):\r\n",
    "\r\n",
    "            for batch_idx, batch in enumerate(batches):                   # Looping over the batches\r\n",
    "                estimated_qs_t_list = []\r\n",
    "                current_states, optimal_actions, next_states = self.process_batch(batch)\r\n",
    "\r\n",
    "                # Prediction on S(t) and all actions\r\n",
    "                for action in self.action_set:                  # Iterating and calculating the value for each action\r\n",
    "                    input_vector = self.get_input_vector(current_states, action)\r\n",
    "                    estimated_qs_t_list.append(self.target_model.predict(input_vector))\r\n",
    "                \r\n",
    "                estimated_qs_vec_t = self.get_batch_vector_out(estimated_qs_t_list)\r\n",
    "                predicted_actions_t = self.greedy(estimated_qs_vec_t, epsilon= EPSILON)\r\n",
    "                rewards_t = self.get_reward(predicted_actions_t, optimal_actions)\r\n",
    "\r\n",
    "                # Prediction on S(t+1) and all actions\r\n",
    "                for action in self.action_set:                  # Iterating and calculating the value for each action\r\n",
    "                    input_vector = self.get_input_vector(next_states, action)\r\n",
    "                    estimated_qs_t_list.append(self.target_model.predict(input_vector))\r\n",
    "                \r\n",
    "                estimated_qs_t_vec = self.get_batch_vector_out(estimated_qs_t_list)\r\n",
    "                predicted_actions_tplus_one = self.greedy(estimated_qs_t_vec, epsilon= EPSILON)\r\n",
    "                \r\n",
    "                # Prediction with S(t+1) and a_cap(t+1)\r\n",
    "                input_vector = np.hstack((next_states, predicted_actions_tplus_one))\r\n",
    "                estimated_qs_t_plus_one = self.target_model.predict(input_vector).reshape(-1)\r\n",
    "                \r\n",
    "                # Calculation of qref\r\n",
    "                qref = rewards_t + LAMBDA * estimated_qs_t_plus_one\r\n",
    "\r\n",
    "                input_train_vector = np.hstack((current_states, predicted_actions_t))\r\n",
    "                loss, accuracy = self.model.train_on_batch(input_train_vector, qref, reset_metrics= False)\r\n",
    "                \r\n",
    "                print(\" -------------------------------------------------- \")\r\n",
    "                print(\"In epoch {}/{} epochs, batch {}/{} batches:\".format(epoch, EPOCHS, batch_idx, self.data.n_train_batches))\r\n",
    "                print(\"Accuracy: {}\".format(accuracy))\r\n",
    "                print(\"Loss: {}\".format(loss))\r\n",
    "                print(\" -------------------------------------------------- \")\r\n",
    "\r\n",
    "                # If counter reaches set value, update target network with weights of main network\r\n",
    "                if self.target_update_counter > UPDATE_TARGET_EVERY:\r\n",
    "                    self.target_model.set_weights(self.model.get_weights())\r\n",
    "                    self.target_update_counter = 0\r\n",
    "                \r\n",
    "                self.target_update_counter += 1\r\n",
    "    \r\n",
    "    def test(self):\r\n",
    "        batches = self.data.test_batches\r\n",
    "        \r\n",
    "        accuracy = 0\r\n",
    "\r\n",
    "        for batch_idx, batch in enumerate(batches):                             # Looping over the batches\r\n",
    "            current_states, optimal_actions, _ = self.process_batch(batch)      # Get the data from the batch\r\n",
    "            estimated_qs_list = []\r\n",
    "\r\n",
    "            for action in self.action_set:                                      # Iterating and predicting the value for each action\r\n",
    "                input_vector = self.get_input_vector(current_states, action)        \r\n",
    "                estimated_qs_list.append(self.model.predict(input_vector))\r\n",
    "\r\n",
    "            estimated_qs_vec = self.get_batch_vector_out(estimated_qs_list).squeeze()     # Get the vectorized output\r\n",
    "            predicted_actions = self.greedy(estimated_qs_vec, epsilon= 1.0).squeeze()     # Since we are testing so we need no exploration, we are only greedy now (eps=1.0)\r\n",
    "\r\n",
    "            curr_batch_accuracy = np.mean(np.equal(estimated_qs_vec, predicted_actions).astype(np.uint32))\r\n",
    "            accuracy += curr_batch_accuracy / len(batches)\r\n",
    "        \r\n",
    "        return accuracy\r\n",
    "        print(\"Finished testing on the testing dataset with accuracy {}\".format(accuracy))\r\n",
    "\r\n",
    "    #TODO: single predict function\r\n",
    "    #def predict(self, state):\r\n",
    "\r\n",
    "\r\n",
    "            \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Training our model\r\n",
    "data = DataLoader(\"new_data.csv\", batch_size= BATCH_SIZE)           # Importing the dataset using our dataloader\r\n",
    "dq_net = DeepQNet(dataset= data)                                    # Creating our DQNet\r\n",
    "dq_net.summary()                                                    # Printing the model contents\r\n",
    "dq_net.train()                                                      # Calling the train function"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset successfully loaded with 171 training batches, and 19 testing batches with 190 batch size.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 128)               3584      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 0/171 batches:\n",
      "Accuracy: 0.0\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 1/171 batches:\n",
      "Accuracy: 0.0029296875\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 2/171 batches:\n",
      "Accuracy: 0.001953125\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 3/171 batches:\n",
      "Accuracy: 0.00244140625\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 4/171 batches:\n",
      "Accuracy: 0.0027343749534338713\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 5/171 batches:\n",
      "Accuracy: 0.0026041667442768812\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 6/171 batches:\n",
      "Accuracy: 0.0022321429569274187\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 7/171 batches:\n",
      "Accuracy: 0.057861328125\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 8/171 batches:\n",
      "Accuracy: 0.1004774272441864\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 9/171 batches:\n",
      "Accuracy: 0.13398437201976776\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 10/171 batches:\n",
      "Accuracy: 0.16122159361839294\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 11/171 batches:\n",
      "Accuracy: 0.1866862028837204\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n",
      " -------------------------------------------------- \n",
      "In epoch 0/10 epochs, batch 12/171 batches:\n",
      "Accuracy: 0.2109375\n",
      "Loss: inf\n",
      " -------------------------------------------------- \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-39553785283f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdq_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepQNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m                                    \u001b[1;31m# Creating our DQNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdq_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                                    \u001b[1;31m# Printing the model contents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdq_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                                      \u001b[1;31m# Calling the train function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-fc8f523214d8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_set\u001b[0m\u001b[1;33m:\u001b[0m                  \u001b[1;31m# Iterating and calculating the value for each action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                     \u001b[0minput_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                     \u001b[0mestimated_qs_t_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mestimated_qs_vec_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_vector_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimated_qs_t_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1625\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1626\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    680\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 705\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   2969\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 2971\u001b[1;33m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[0;32m   2972\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2973\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Testing and Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dq_net.test()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving The Model (Checkpoint)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "eded81c4a7c6917c9cbd3629f4297c0af6b02e3629b6d4cad1fc0bc42eaeccd9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}