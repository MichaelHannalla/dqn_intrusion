{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Library Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np                  # Numpy numerical library\r\n",
    "import pandas as pd                 # Pandas for dataframes manipulation\r\n",
    "import tensorflow as tf             # TensorFlow for neural networks and deep learning APIs\r\n",
    "import matplotlib.pyplot as plt     # Plotting\r\n",
    "%matplotlib inline                  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "BATCH_SIZE = 256                # Default batch size\r\n",
    "TRAIN_SPLIT_PERCENT = 0.9       # 90% of the data for training, 10% for testing    \r\n",
    "\r\n",
    "class DataLoader:\r\n",
    "    # Take in a csv file and extracts features and labels\r\n",
    "    def __init__(self, csv_filepath, batch_size):                          \r\n",
    "        \r\n",
    "        self.df_samples = pd.read_csv(csv_filepath)                 # Create a pandas dataframe\r\n",
    "        self.numpy_samples = self.df_samples.to_numpy()\r\n",
    "        \r\n",
    "        self.states_features = self.numpy_samples[:, 1:self.numpy_samples.shape[1]-1]               # Take the feature values for states, also ignore first column for IDs  \r\n",
    "        self.feature_dim = self.states_features.shape[1]                                        \r\n",
    "        self.actions_labels = self.numpy_samples[:, -1].reshape(-1, 1)                              # The action labels separated from the labels\r\n",
    "        self.actions_classes = np.amax(self.actions_labels) + 1                                     # Number of different action classes to set the output layer dimensions (+1 bec starts at zero)\r\n",
    "        self.train_batches, self.test_batches = self.prepare_batches(batch_size, train_split_percent= TRAIN_SPLIT_PERCENT)\r\n",
    "        print(\"Dataset successfully loaded with {} training batches, and {} testing batches with {} batch size.\".format(\r\n",
    "            len(self.train_batches), len(self.test_batches), self.batch_size\r\n",
    "        ))\r\n",
    "        \r\n",
    "    def prepare_batches(self, batch_size, train_split_percent):\r\n",
    "        states_t = self.states_features[:-1, :].copy()           # Considered as S(t)\r\n",
    "        states_t_plus_one = self.states_features[1:, :].copy()   # Considered as S(t+1)\r\n",
    "        actions_star_t = self.actions_labels[:-1, :].copy()      # Considered as a*(t)\r\n",
    "\r\n",
    "        whole_generic_samples = np.hstack((states_t, actions_star_t, states_t_plus_one))            # Stack the whole dataset as described in the paper\r\n",
    "\r\n",
    "        # np.random.shuffle(whole_generic_samples)          # Shuffle the dataset\r\n",
    "        \r\n",
    "        self.n_samples = whole_generic_samples.shape[0]\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.n_batches = np.ceil(self.n_samples / self.batch_size).astype(np.uint32)\r\n",
    "\r\n",
    "        train_batches = []        # Empty list to hold the batches of whole data\r\n",
    "        test_batches = []\r\n",
    "\r\n",
    "        # Prepare the data into batches\r\n",
    "        for i in range(self.n_batches):\r\n",
    "            start = i * batch_size\r\n",
    "            end = (i + 1) * batch_size\r\n",
    "            curr_batch = whole_generic_samples[start:end, :]\r\n",
    "            if (i / self.n_batches) < train_split_percent:    \r\n",
    "                train_batches.append(curr_batch)\r\n",
    "            else:\r\n",
    "                test_batches.append(curr_batch)\r\n",
    "        \r\n",
    "        self.n_train_batches = len(train_batches)\r\n",
    "        self.n_test_batches = len(test_batches)\r\n",
    "        return train_batches, test_batches\r\n",
    "    \r\n",
    "    # Function that takes in the 2D arrays of data and converts lo lists of tuples to be compatible with looping while training\r\n",
    "    # TODO: Enhancing this function\r\n",
    "    def tupelize(self, array):\r\n",
    "        list_of_tuples = list(zip(array.T[0], array.T))\r\n",
    "        return list_of_tuples \r\n",
    "\r\n",
    "    # Function to get the unique rows representing unique states, returns a numpy array of rows\r\n",
    "    def get_unique_rows(self):\r\n",
    "        self.unique_rows = np.unique(self.states_features, axis = 0)\r\n",
    "        return self.unique_rows\r\n",
    "\r\n",
    "    # Get the pandas dataframe for the data, returns a pandas dataframe\r\n",
    "    def get_dataframe(self):    \r\n",
    "        return self.df_samples\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model and Classes Definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "Q_OUT_DIM = 1               # Output dimension\r\n",
    "LEARNING_RATE = 0.001       # Gradient-descent learning rate\r\n",
    "UPDATE_TARGET_EVERY = 5     # Iterations before updating the secondary model     \r\n",
    "EPSILON = 0.8               # Epsilon value for the epsilon greedy policy selection\r\n",
    "LAMBDA = 0.001              # Discount factor for loss calculation\r\n",
    "EPOCHS = 2                  # Number of training epochs\r\n",
    "\r\n",
    "# Creating our main class for our DQN\r\n",
    "class DeepQNet:\r\n",
    "    \r\n",
    "    def __init__(self, dataset):\r\n",
    "        self.data = dataset                                         # Storing the data in our QNet            \r\n",
    "        self.input_dim = dataset.feature_dim + 1                    # State feature dim + 1 (for actions)\r\n",
    "        self.output_dim = Q_OUT_DIM                               \r\n",
    "        \r\n",
    "        self.model = self.create_model()                            # Main model that gets trained every step \r\n",
    "        self.target_model = self.create_model()                     # Target model we predict against each step\r\n",
    "        self.target_model.set_weights(self.model.get_weights())     # To make all the initial weights the same\r\n",
    "\r\n",
    "        # Defining the action-set\r\n",
    "        self.action_set = np.arange(self.data.actions_classes).astype(np.uint16).tolist() # List of all possible actions [0, 1, ... actions_classes]\r\n",
    "\r\n",
    "        # Used to count when to update target network with main network's weights\r\n",
    "        self.target_update_counter = 0\r\n",
    "    \r\n",
    "    def create_model(self):\r\n",
    "        # Definition of the neural network architecture mentioned in the paper (3 relu feedforward layers)\r\n",
    "        model = tf.keras.Sequential()\r\n",
    "        model.add(tf.keras.layers.Input(self.input_dim))                        # Input dimension of the state-vector\r\n",
    "        model.add(tf.keras.layers.Dense(128, activation= \"relu\"))\r\n",
    "        model.add(tf.keras.layers.Dense(128, activation= \"relu\"))\r\n",
    "        model.add(tf.keras.layers.Dense(self.output_dim, activation= \"relu\"))       # Output is value function\r\n",
    "        model.compile(loss=\"mse\", optimizer=tf.optimizers.Adam(lr= LEARNING_RATE), metrics=['accuracy'])\r\n",
    "        return model\r\n",
    "\r\n",
    "    # Prints the model details\r\n",
    "    def summary(self):\r\n",
    "        self.model.summary()\r\n",
    "\r\n",
    "    def get_reward(self, predicted_actions, optimal_actions):\r\n",
    "        predicted_actions = np.asarray(predicted_actions).reshape(-1)\r\n",
    "        optimal_actions = np.asarray(optimal_actions).reshape(-1)\r\n",
    "        reward_vector = np.equal(predicted_actions, optimal_actions).astype(np.uint32)\r\n",
    "        return reward_vector\r\n",
    "\r\n",
    "    # Function to implement the epsilon-greedy policy selection, returns the index of the selected action\r\n",
    "    def greedy(self, actions_values_vec, epsilon):\r\n",
    "        num_in_curr_batch = actions_values_vec.shape[1]\r\n",
    "        selections = []\r\n",
    "        for i in range(num_in_curr_batch):\r\n",
    "            p = np.random.uniform(low=0.0, high=1.0)\r\n",
    "            if p < epsilon:\r\n",
    "                curr_actions_values = actions_values_vec[:, i].reshape(-1)\r\n",
    "                selections.append(np.argmax(curr_actions_values))\r\n",
    "            else:\r\n",
    "                random_selection = np.random.randint(low=0, high=self.data.actions_classes)\r\n",
    "                selections.append(random_selection)\r\n",
    "        \r\n",
    "        selections = np.asarray(selections).reshape(-1, 1)\r\n",
    "\r\n",
    "        return selections\r\n",
    "\r\n",
    "    # Function to process the batch and split the S(t), a*(t), and S(t+1)\r\n",
    "    def process_batch(self, batch):\r\n",
    "        current_states = batch[:, :self.data.feature_dim]\r\n",
    "        optimal_actions = batch[:, self.data.feature_dim]\r\n",
    "        next_states = batch[:, self.data.feature_dim+1 :]\r\n",
    "        return current_states, optimal_actions, next_states\r\n",
    "\r\n",
    "    def get_input_vector(self, current_states, action):\r\n",
    "        action_vector = np.full((current_states.shape[0], 1), fill_value= action)\r\n",
    "        input_vector =  np.hstack((current_states, action_vector))\r\n",
    "        return input_vector\r\n",
    "\r\n",
    "    # Function to get the vectorized output of the batched-samples\r\n",
    "    def get_batch_vector_out(self, lst):\r\n",
    "        nparr = np.asarray(lst).squeeze() \r\n",
    "        if nparr.ndim < 2:\r\n",
    "            nparr = np.reshape(nparr, (nparr.shape[0], 1))\r\n",
    "        return nparr\r\n",
    "\r\n",
    "    def train(self):\r\n",
    "        \r\n",
    "        batches = self.data.train_batches               # Get the batches\r\n",
    "        self.target_update_counter = 0                  # The update counter \r\n",
    "\r\n",
    "        for epoch in range(EPOCHS):\r\n",
    "\r\n",
    "            for batch_idx, batch in enumerate(batches):                   # Looping over the batches\r\n",
    "                current_states, optimal_actions, next_states = self.process_batch(batch)\r\n",
    "\r\n",
    "                # Prediction on S(t) and all actions\r\n",
    "                estimated_qs_t_list = []\r\n",
    "                for action in self.action_set:                  # Iterating and calculating the value for each action\r\n",
    "                    input_vector = self.get_input_vector(current_states, action)\r\n",
    "                    estimated_qs_t_list.append(self.target_model.predict(input_vector))\r\n",
    "                    print(np.unique(self.target_model.predict(input_vector)))\r\n",
    "\r\n",
    "                estimated_qs_vec_t = self.get_batch_vector_out(estimated_qs_t_list)\r\n",
    "                predicted_actions_t = self.greedy(estimated_qs_vec_t, epsilon= EPSILON)\r\n",
    "                rewards_t = self.get_reward(predicted_actions_t, optimal_actions)\r\n",
    "            \r\n",
    "\r\n",
    "                # Prediction on S(t+1) and all actions\r\n",
    "                estimated_qs_t_plus_one_list = []\r\n",
    "                for action in self.action_set:                  # Iterating and calculating the value for each action\r\n",
    "                    input_vector = self.get_input_vector(next_states, action)\r\n",
    "                    estimated_qs_t_plus_one_list.append(self.target_model.predict(input_vector))\r\n",
    "                \r\n",
    "                estimated_qs_vec_t_plus_one = self.get_batch_vector_out(estimated_qs_t_plus_one_list)\r\n",
    "                predicted_actions_tplus_one = self.greedy(estimated_qs_vec_t_plus_one, epsilon= 1.0)     # Taking the always argmax (epsilon = 1.0)\r\n",
    "                \r\n",
    "                # Prediction with S(t+1) and a_cap(t+1)\r\n",
    "                input_vector = np.hstack((next_states, predicted_actions_tplus_one))\r\n",
    "                q_cap_t_plus_one = self.target_model.predict(input_vector).reshape(-1)\r\n",
    "                #print(q_cap_t_plus_one)\r\n",
    "                \r\n",
    "                # Calculation of qref\r\n",
    "                qref = rewards_t + LAMBDA * q_cap_t_plus_one\r\n",
    "                \r\n",
    "                input_train_vector = np.hstack((current_states, predicted_actions_t))\r\n",
    "                loss, accuracy = self.model.train_on_batch(input_train_vector, qref, reset_metrics= False)\r\n",
    "                \r\n",
    "                # print(\" -------------------------------------------------- \")\r\n",
    "                # print(\"In epoch {}/{} epochs, batch {}/{} batches:\".format(epoch, EPOCHS, batch_idx, self.data.n_train_batches))\r\n",
    "                # print(\"Accuracy: {}\".format(accuracy))\r\n",
    "                # print(\"Loss: {}\".format(loss))\r\n",
    "                # print(\" -------------------------------------------------- \")\r\n",
    "                \r\n",
    "                # If counter reaches set value, update target network with weights of main network\r\n",
    "                if self.target_update_counter > UPDATE_TARGET_EVERY:\r\n",
    "                    self.target_model.set_weights(self.model.get_weights())\r\n",
    "                    self.target_update_counter = 0\r\n",
    "                \r\n",
    "                self.target_update_counter += 1\r\n",
    "    \r\n",
    "    def test(self):\r\n",
    "        batches = self.data.test_batches\r\n",
    "        \r\n",
    "        accuracy = 0\r\n",
    "\r\n",
    "        for batch_idx, batch in enumerate(batches):                             # Looping over the batches\r\n",
    "            current_states, optimal_actions, _ = self.process_batch(batch)      # Get the data from the batch\r\n",
    "            estimated_qs_list = []\r\n",
    "\r\n",
    "            for action in self.action_set:                                      # Iterating and predicting the value for each action\r\n",
    "                input_vector = self.get_input_vector(current_states, action)        \r\n",
    "                estimated_qs_list.append(self.model.predict(input_vector))\r\n",
    "\r\n",
    "            estimated_qs_vec = self.get_batch_vector_out(estimated_qs_list).squeeze()     # Get the vectorized output\r\n",
    "            predicted_actions = self.greedy(estimated_qs_vec, epsilon= 1.0).squeeze()     # Since we are testing so we need no exploration, we are only greedy now (eps=1.0)\r\n",
    "\r\n",
    "            break\r\n",
    "\r\n",
    "            curr_batch_accuracy = np.mean(np.equal(predicted_actions, optimal_actions).astype(np.uint32))\r\n",
    "            accuracy += curr_batch_accuracy / len(batches)\r\n",
    "        \r\n",
    "        \r\n",
    "        print(\"Finished testing on the testing dataset with accuracy {}\".format(accuracy))\r\n",
    "        return accuracy\r\n",
    "\r\n",
    "    #TODO: single predict function\r\n",
    "    #def predict(self, state):\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Training our model\r\n",
    "data = DataLoader(\"new_data.csv\", batch_size= BATCH_SIZE)           # Importing the dataset using our dataloader\r\n",
    "dq_net = DeepQNet(dataset= data)                                    # Creating our DQNet\r\n",
    "dq_net.summary()                                                    # Printing the model contents\r\n",
    "dq_net.train()                                                      # Calling the train function"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset successfully loaded with 342 training batches, and 37 testing batches with 256 batch size.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               3584      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,225\n",
      "Trainable params: 20,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[ 0.         8.691421   8.787829   8.917019   8.991404   9.128336\n",
      "  9.215119   9.257777   9.341758   9.449714   9.476493   9.50119\n",
      "  9.606233   9.697133   9.725859   9.75819    9.785926   9.793065\n",
      "  9.832791   9.839961   9.840704   9.850433   9.863639   9.86833\n",
      "  9.931504   9.960917   9.97253    9.981476   9.983035   9.987961\n",
      " 10.000889  10.006693  10.017543  10.0272455 10.060555  10.096375\n",
      " 10.141422 ]\n",
      "[0.        8.512005  8.611835  8.741024  8.815411  8.95234   9.03912\n",
      " 9.081778  9.165762  9.275789  9.302572  9.32727   9.4332695 9.552483\n",
      " 9.57983   9.611797  9.63818   9.645018  9.692363  9.693388  9.701226\n",
      " 9.711658  9.723677  9.728368  9.7814455 9.8096075 9.817295  9.826244\n",
      " 9.827808  9.832433  9.842286  9.848082  9.867763  9.877458  9.91077\n",
      " 9.946587  9.99164  ]\n",
      "[0.        8.332838  8.435844  8.565024  8.639411  8.776345  8.863127\n",
      " 8.906626  8.990957  9.101863  9.129089  9.1540365 9.257977  9.401378\n",
      " 9.4287195 9.460688  9.487076  9.49391   9.541252  9.547896  9.561263\n",
      " 9.571691  9.583716  9.588407  9.631391  9.654373  9.662067  9.67071\n",
      " 9.67257   9.673827  9.683681  9.68948   9.717977  9.7276745 9.760981\n",
      " 9.796805  9.841855 ]\n",
      "[0.        8.156843  8.259849  8.389032  8.46342   8.6003475 8.688134\n",
      " 8.732701  8.817026  8.928183  8.956125  8.9810705 9.0777025 9.222467\n",
      " 9.277609  9.309578  9.335963  9.342799  9.3901415 9.39679   9.421302\n",
      " 9.43173   9.443756  9.448445  9.481339  9.499141  9.506618  9.512106\n",
      " 9.515224  9.517342  9.52508   9.530878  9.568193  9.577892  9.6112\n",
      " 9.647019  9.692071 ]\n",
      "[0.        7.9808493 8.083853  8.213038  8.287423  8.424354  8.514211\n",
      " 8.558781  8.643102  8.755186  8.778503  8.802313  8.897426  9.042192\n",
      " 9.1225395 9.158469  9.184856  9.19169   9.239034  9.245682  9.281341\n",
      " 9.283323  9.303796  9.308484  9.328997  9.343909  9.348004  9.353496\n",
      " 9.356623  9.361885  9.366466  9.378496  9.418404  9.428109  9.461413\n",
      " 9.497236  9.542286 ]\n",
      "[0.        7.8048506 7.9078546 8.037044  8.111427  8.249708  8.340286\n",
      " 8.384854  8.469176  8.574909  8.598227  8.622035  8.717147  8.861915\n",
      " 8.942262  9.004703  9.033743  9.04058   9.087923  9.094571  9.132214\n",
      " 9.136817  9.163838  9.168526  9.179209  9.188465  9.189407  9.194893\n",
      " 9.198019  9.203283  9.207866  9.228712  9.268623  9.278322  9.311626\n",
      " 9.347447  9.3925   ]\n",
      "[0.        7.6288586 7.731862  7.8610454 7.936947  8.075783  8.166362\n",
      " 8.210932  8.292457  8.394634  8.4179535 8.441758  8.536874  8.681645\n",
      " 8.7619915 8.824431  8.879778  8.889471  8.9368105 8.943462  8.981107\n",
      " 8.985707  9.02387   9.028563  9.029856  9.030799  9.030991  9.036292\n",
      " 9.039411  9.044678  9.049263  9.078927  9.1188345 9.128536  9.161849\n",
      " 9.197665  9.233111 ]\n",
      "[0.        7.4528637 7.5558634 7.685047  7.763015  7.9018583 7.992437\n",
      " 8.033882  8.112181  8.214358  8.237676  8.261484  8.3566    8.501364\n",
      " 8.581713  8.644157  8.699507  8.731524  8.785706  8.792355  8.830001\n",
      " 8.8345995 8.870973  8.872193  8.877688  8.880806  8.882751  8.883913\n",
      " 8.886077  8.888603  8.898847  8.929138  8.969052  8.978751  9.008516\n",
      " 9.033899  9.064955 ]\n",
      "[ 0.          0.08733684  0.28262874  0.67785513  1.0401278   1.3440428\n",
      "  1.6489754   1.9546993   2.1065364   2.274717    3.036658    3.315786\n",
      "  3.4607303   3.6154864   3.738484    4.1012244   4.444542    4.600234\n",
      "  4.7059464   5.3486986   5.589082    5.703489    5.852586    5.9475365\n",
      "  6.072691    6.22928     6.514126    6.696018    6.7748036   6.8352623\n",
      "  7.07862     7.1696806   7.337218    7.3994546   7.499559    7.7066174\n",
      "  7.829391    7.950216    8.064531    8.093094    8.142306    8.268453\n",
      " 10.128264  ]\n",
      "[0.         0.05335343 0.44811863 0.80116034 1.1004293  1.405354\n",
      " 1.7050261  1.8442183  2.0124035  2.77812    3.0722547  3.230023\n",
      " 3.4212923  3.544287   3.907021   4.2503405  4.406031   4.5115366\n",
      " 5.1544256  5.411005   5.525412   5.700915   5.7958617  5.9210157\n",
      " 6.0776052  6.3677897  6.5483932  6.624963   6.6832995  6.9266586\n",
      " 7.0177174  7.1852555  7.2474937  7.3309755  7.525403   7.652182\n",
      " 7.7802935  7.8946004  7.923174   7.957293   8.073824   9.9816885 ]\n",
      "[0.         0.21837944 0.5575428  0.8568143  1.1617377  1.4614148\n",
      " 1.599745   1.7575115  2.5346406  2.844756   3.0008953  3.193767\n",
      " 3.3500881  3.7128255  4.0561438  4.2118335  4.3173323  4.960148\n",
      " 5.222978   5.347337   5.5322285  5.6441884  5.766106   5.9190063\n",
      " 6.215823   6.396427   6.473001   6.5313377  6.7746964  6.8657537\n",
      " 7.033295   7.0782504  7.1503983  7.3443813  7.4732018  7.6100965\n",
      " 7.7246776  7.753246   7.787364   7.8925433  9.8324    ]\n",
      "[0.        0.3139264 0.6131939 0.918124  1.2177924 1.3561299 1.5138946\n",
      " 2.3063931 2.6192684 2.775407  2.9633703 3.1358223 3.5186222 3.8619475\n",
      " 4.0176387 4.123137  4.765877  5.0271497 5.158812  5.3455186 5.4734845\n",
      " 5.6027346 5.756904  6.0638647 6.244465  6.321039  6.3793736 6.622733\n",
      " 6.7137938 6.8637133 6.901067  6.969542  7.1636505 7.291989  7.4328895\n",
      " 7.554751  7.5860224 7.6272836 7.730705  9.68262  ]\n",
      "[0.         0.07031089 0.36957806 0.6745067  0.9741806  1.1125098\n",
      " 1.2702749  2.0781493  2.3937812  2.5499198  2.7378821  2.9051132\n",
      " 3.324429   3.667746   3.8234367  3.9289408  4.562233   4.821111\n",
      " 4.957057   5.1557455  5.283707   5.439365   5.6049366  5.9118986\n",
      " 6.092506   6.1690755  6.227412   6.4707713  6.5618343  6.686528\n",
      " 6.7225804  6.788685   6.982921   7.1107745  7.2556763  7.3927507\n",
      " 7.42839    7.469645   7.573075   9.532833  ]\n",
      "[0.         0.12596333 0.43088776 0.73056513 0.8688932  1.0371695\n",
      " 1.8569808  2.1682901  2.324429   2.512391   2.6790276  3.1302264\n",
      " 3.4659853  3.6210284  3.7236466  4.3562036  4.615075   4.751015\n",
      " 4.961809   5.093935   5.2834063  5.452981   5.7599325  5.940537\n",
      " 6.0171146  6.07545    6.318805   6.3911695  6.5093412  6.5417256\n",
      " 6.6078277  6.8021874  6.9295545  7.077995   7.2351184  7.2707524\n",
      " 7.3120117  7.415436   9.383051  ]\n",
      "[0.         0.18727434 0.48863715 0.6452311  0.82256955 1.6483549\n",
      " 1.942806   2.0976195  2.2847977  2.4499779  2.9243522  3.260052\n",
      " 3.4150968  3.5177145  4.15017    4.4090414  4.544976   4.7645073\n",
      " 4.9044423  5.105151   5.3010154  5.6079717  5.7885766  5.86515\n",
      " 5.9234853  6.147635   6.2139926  6.3302426  6.360871   6.4269753\n",
      " 6.6214585  6.7483397  6.9075484  7.077485   7.1131225  7.1543818\n",
      " 7.2578044  9.224612  ]\n",
      "[0.         0.27403134 0.4306289  0.6079651  1.437696   1.7284474\n",
      " 1.8688712  2.0511844  2.2163577  2.7069218  3.0541282  3.2091691\n",
      " 3.3117886  3.9441338  4.203008   4.338944   4.5721345  4.7162724\n",
      " 4.9267926  5.14905    5.4560127  5.636616   5.713188   5.771524\n",
      " 5.9704523  6.036804   6.1493845  6.180014   6.246118   6.4407277\n",
      " 6.5757365  6.7386255  6.9198494  6.955486   6.9967475  7.100171\n",
      " 9.055972  ]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n",
      "[0.]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-39553785283f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdq_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepQNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m                                    \u001b[1;31m# Creating our DQNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdq_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                                    \u001b[1;31m# Printing the model contents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdq_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                                      \u001b[1;31m# Calling the train function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-39cb44fa991d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m                     \u001b[0minput_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                     \u001b[0mestimated_qs_t_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mestimated_qs_vec_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_vector_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimated_qs_t_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1625\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1626\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    680\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 705\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32mC:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   2969\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 2971\u001b[1;33m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[0;32m   2972\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2973\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Testing and Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dq_net.test()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving The Model (Checkpoint)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "eded81c4a7c6917c9cbd3629f4297c0af6b02e3629b6d4cad1fc0bc42eaeccd9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}